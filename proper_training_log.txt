2025-11-03 20:44:29,007 - INFO - ================================================================================
2025-11-03 20:44:29,007 - INFO - PROPER SSH BRUTEFORCE DETECTION TRAINING
2025-11-03 20:44:29,007 - INFO - Using Separate BETH Train/Test Files
2025-11-03 20:44:29,007 - INFO - ================================================================================
2025-11-03 20:44:29,007 - INFO - === Loading Separate BETH Files ===
2025-11-03 20:44:29,007 - INFO - Loading training data: datasets/labelled_training_data.csv
2025-11-03 20:44:31,372 - INFO - ‚úì Training data: 763,144 samples
2025-11-03 20:44:31,372 - INFO - Loading testing data: datasets/labelled_testing_data.csv
2025-11-03 20:44:32,019 - INFO - ‚úì Testing data: 188,967 samples
2025-11-03 20:44:32,019 - INFO - 
--- Training Data Labels ---
2025-11-03 20:44:32,068 - INFO - 
sus  evil
0    0       761875
1    0         1269
Name: count, dtype: int64
2025-11-03 20:44:32,068 - INFO - 
--- Testing Data Labels ---
2025-11-03 20:44:32,078 - INFO - 
sus  evil
1    1       158432
0    0        17508
1    0        13027
Name: count, dtype: int64
2025-11-03 20:44:32,089 - INFO - 
Training attacks: 1,269 / 763,144 (0.17%)
2025-11-03 20:44:32,090 - INFO - Testing attacks: 171,459 / 188,967 (90.73%)
2025-11-03 20:44:32,090 - INFO - 
=== Feature Extraction ===
2025-11-03 20:44:32,090 - INFO - Extracting features from 763,144 samples...
2025-11-03 20:44:32,291 - INFO - ‚úì Extracted 13 features
2025-11-03 20:44:32,292 - INFO - Extracting features from 188,967 samples...
2025-11-03 20:44:32,343 - INFO - ‚úì Extracted 13 features
2025-11-03 20:44:32,343 - INFO - Training features shape: (763144, 13)
2025-11-03 20:44:32,343 - INFO - Testing features shape: (188967, 13)
2025-11-03 20:44:32,343 - INFO - 
=== Feature Scaling ===
2025-11-03 20:44:32,684 - INFO - ‚úì Features scaled
2025-11-03 20:44:32,684 - INFO - 
=== Training Random Forest ===
2025-11-03 20:44:32,684 - INFO - Training model...
2025-11-03 20:44:39,401 - INFO - 
=== Training Decision Tree ===
2025-11-03 20:44:40,056 - INFO - 
=== Training Isolation Forest (unsupervised) ===
2025-11-03 20:44:43,255 - INFO - 
=== Evaluation on Independent Test Set ===
2025-11-03 20:44:43,975 - INFO - 
=== Training Logistic Regression (for comparison) ===
2025-11-03 20:44:44,942 - INFO - 
üìä REAL Performance Metrics:
2025-11-03 20:44:44,942 - INFO -   RF Accuracy: 0.9067
2025-11-03 20:44:44,942 - INFO -   LR Accuracy: 0.9454
2025-11-03 20:44:44,942 - INFO -   DT Accuracy: 0.9511
2025-11-03 20:44:44,942 - INFO -   Ensemble (RF+LR+DT+ISO) Accuracy: 0.9453
2025-11-03 20:44:44,981 - INFO -   Ensemble ROC-AUC:  0.9787
2025-11-03 20:44:44,981 - INFO - 
üìà Confusion Matrix:
2025-11-03 20:44:44,981 - INFO -   True Positives:  161,562
2025-11-03 20:44:44,981 - INFO -   True Negatives:  17,077
2025-11-03 20:44:44,981 - INFO -   False Positives: 431
2025-11-03 20:44:44,981 - INFO -   False Negatives: 9,897
2025-11-03 20:44:44,981 - INFO -   Precision: 0.9973
2025-11-03 20:44:44,981 - INFO -   Recall: 0.9423
2025-11-03 20:44:44,981 - INFO - 
üìã Detailed Classification Report (Ensemble):
2025-11-03 20:44:45,058 - INFO - 
              precision    recall  f1-score   support

      Normal       0.63      0.98      0.77     17508
      Attack       1.00      0.94      0.97    171459

    accuracy                           0.95    188967
   macro avg       0.82      0.96      0.87    188967
weighted avg       0.96      0.95      0.95    188967

2025-11-03 20:44:45,073 - INFO - 
üîç Top 10 Feature Importances:
2025-11-03 20:44:45,079 - INFO - 
            feature  importance
2            userId    0.527325
0         processId    0.121131
12     is_root_user    0.098765
1   parentProcessId    0.089197
7        is_systemd    0.083314
5       returnValue    0.030065
6           is_sshd    0.027107
3           eventId    0.014350
4           argsNum    0.005732
11             hour    0.001363
2025-11-03 20:44:45,081 - INFO - 
‚úì Model saved: models/random_forest_proper.pkl
2025-11-03 20:44:45,081 - INFO - Logistic Regression Accuracy: 0.9454
2025-11-03 20:44:45,081 - INFO - Random Forest Accuracy: 0.9067
2025-11-03 20:44:45,081 - INFO - Decision Tree Accuracy: 0.9511
2025-11-03 20:44:45,081 - INFO - Ensemble Accuracy: 0.9453
2025-11-03 20:44:45,082 - INFO - ‚úì Logistic Regression saved: models/logistic_regression_proper.pkl
2025-11-03 20:44:45,082 - INFO - 
================================================================================
2025-11-03 20:44:45,082 - INFO - PROPER TRAINING COMPLETED
2025-11-03 20:44:45,082 - INFO - ================================================================================
2025-11-03 20:44:45,082 - INFO - Now using truly independent test data!
2025-11-03 20:44:45,082 - INFO - Training samples: 763,144
2025-11-03 20:44:45,082 - INFO - Testing samples: 188,967
2025-11-03 20:44:45,082 - INFO - Final RF Accuracy: 0.9067
2025-11-03 20:44:45,082 - INFO - Final LR Accuracy: 0.9454
2025-11-03 20:44:45,082 - INFO - Final DT Accuracy: 0.9511
2025-11-03 20:44:45,082 - INFO - Final Ensemble Accuracy: 0.9453
2025-11-04 10:25:59,607 - INFO - ================================================================================
2025-11-04 10:25:59,607 - INFO - SSH BRUTEFORCE DETECTION - ENSEMBLE TRAINING
2025-11-04 10:25:59,607 - INFO - 1 Supervised (Logistic Regression) + 1 Unsupervised (Isolation Forest)
2025-11-04 10:25:59,607 - INFO - Using Separate BETH Train/Test Files
2025-11-04 10:25:59,607 - INFO - ================================================================================
2025-11-04 10:25:59,608 - INFO - === Loading Separate BETH Files ===
2025-11-04 10:25:59,608 - INFO - Loading training data: datasets/labelled_training_data.csv
2025-11-04 10:26:03,554 - INFO - ‚úì Training data: 763,144 samples
2025-11-04 10:26:03,554 - INFO - Loading testing data: datasets/labelled_testing_data.csv
2025-11-04 10:26:04,677 - INFO - ‚úì Testing data: 188,967 samples
2025-11-04 10:26:04,677 - INFO - 
--- Training Data Labels ---
2025-11-04 10:26:04,752 - INFO - 
sus  evil
0    0       761875
1    0         1269
Name: count, dtype: int64
2025-11-04 10:26:04,752 - INFO - 
--- Testing Data Labels ---
2025-11-04 10:26:04,774 - INFO - 
sus  evil
1    1       158432
0    0        17508
1    0        13027
Name: count, dtype: int64
2025-11-04 10:26:04,792 - INFO - 
Training attacks: 1,269 / 763,144 (0.17%)
2025-11-04 10:26:04,793 - INFO - Testing attacks: 171,459 / 188,967 (90.73%)
2025-11-04 10:26:04,793 - INFO - 
=== Feature Extraction ===
2025-11-04 10:26:04,793 - INFO - Extracting features from 763,144 samples...
2025-11-04 10:26:05,055 - INFO - ‚úì Extracted 13 features
2025-11-04 10:26:05,056 - INFO - Extracting features from 188,967 samples...
2025-11-04 10:26:05,132 - INFO - ‚úì Extracted 13 features
2025-11-04 10:26:05,132 - INFO - Training features shape: (763144, 13)
2025-11-04 10:26:05,132 - INFO - Testing features shape: (188967, 13)
2025-11-04 10:26:05,133 - INFO - 
=== Feature Scaling ===
2025-11-04 10:26:05,737 - INFO - ‚úì Features scaled
2025-11-04 10:26:05,737 - INFO - 
=== Training Supervised Model: Logistic Regression ===
2025-11-04 10:26:05,737 - INFO - Uses labeled data (is_attack) to learn patterns
2025-11-04 10:26:05,737 - INFO - Training Logistic Regression...
2025-11-04 10:26:07,443 - INFO - ‚úì Logistic Regression trained
2025-11-04 10:26:07,444 - INFO - 
=== Training Unsupervised Model: Isolation Forest ===
2025-11-04 10:26:07,444 - INFO - Isolation Forest learns normal behavior from training data (NO labels used)
2025-11-04 10:26:07,444 - INFO - Why Isolation Forest? See explanation at end of training log.
2025-11-04 10:26:07,514 - INFO - Training on 761,875 normal samples (to learn normal behavior)
2025-11-04 10:26:07,514 - INFO - Training Isolation Forest...
2025-11-04 10:26:13,709 - INFO - ‚úì Isolation Forest trained
2025-11-04 10:26:13,709 - INFO - 
=== Evaluation on Independent Test Set ===
2025-11-04 10:26:15,236 - INFO - 
üìä Performance Metrics:
2025-11-04 10:26:15,236 - INFO -   Logistic Regression (Supervised): 0.9456
2025-11-04 10:26:15,236 - INFO -   Isolation Forest (Unsupervised):   0.9244
2025-11-04 10:26:15,236 - INFO -   Ensemble (LR + IF):                0.9456
2025-11-04 10:26:15,260 - INFO -   Ensemble ROC-AUC:                0.9766
2025-11-04 10:26:15,260 - INFO - 
üìà Confusion Matrix (Ensemble):
2025-11-04 10:26:15,260 - INFO -   True Positives:  161,264
2025-11-04 10:26:15,261 - INFO -   True Negatives:  17,424
2025-11-04 10:26:15,261 - INFO -   False Positives: 84
2025-11-04 10:26:15,261 - INFO -   False Negatives: 10,195
2025-11-04 10:26:15,261 - INFO -   Precision: 0.9995
2025-11-04 10:26:15,261 - INFO -   Recall (Detection Rate): 0.9405
2025-11-04 10:26:15,261 - INFO -   False Alarm Rate: 0.0048
2025-11-04 10:26:15,261 - INFO - 
üìã Detailed Classification Report (Ensemble):
2025-11-04 10:26:15,308 - INFO - 
              precision    recall  f1-score   support

      Normal       0.63      1.00      0.77     17508
      Attack       1.00      0.94      0.97    171459

    accuracy                           0.95    188967
   macro avg       0.82      0.97      0.87    188967
weighted avg       0.97      0.95      0.95    188967

2025-11-04 10:26:15,308 - INFO - 
=== Saving Ensemble Model ===
2025-11-04 10:26:15,356 - INFO - ‚úì Ensemble model saved: models/ensemble.pkl
2025-11-04 10:26:15,356 - INFO - 
================================================================================
2025-11-04 10:26:15,356 - INFO - WHY ISOLATION FOREST? (vs Other Unsupervised Models)
2025-11-04 10:26:15,356 - INFO - ================================================================================
2025-11-04 10:26:15,356 - INFO - 
    Isolation Forest vs Other Unsupervised Models:
    
    1. ISOLATION FOREST (Chosen) ‚úÖ
       - Fast training & inference (O(n log n))
       - Handles high-dimensional data well (13 features)
       - No assumptions about data distribution
       - Works well with imbalanced data (99.83% normal in training)
       - Good for anomaly detection in network logs
       - Memory efficient (tree-based)
    
    2. DBSCAN (Clustering-based)
       - Needs tuning of eps (distance) and min_samples
       - Struggles with high-dimensional data (curse of dimensionality)
       - Slower on large datasets
       - Hard to interpret clusters
    
    3. One-Class SVM
       - Slower training (O(n¬≤) complexity)
       - Requires kernel selection (RBF, linear, etc.)
       - Memory intensive for large datasets
       - Less interpretable
    
    4. Autoencoder (Deep Learning)
       - Requires more data and GPU
       - Slower training
       - Overkill for this feature space (13 features)
       - Harder to deploy
    
    5. Local Outlier Factor (LOF)
       - Slower than Isolation Forest
       - Sensitive to parameter k (neighbors)
       - Memory intensive
    
    Conclusion: Isolation Forest is ideal for:
    - Real-time SSH log monitoring (fast inference)
    - High-dimensional feature spaces
    - Imbalanced datasets
    - Production deployment (lightweight, interpretable)
    
2025-11-04 10:26:15,356 - INFO - 
================================================================================
2025-11-04 10:26:15,356 - INFO - ENSEMBLE TRAINING COMPLETED
2025-11-04 10:26:15,356 - INFO - ================================================================================
2025-11-04 10:26:15,356 - INFO - Training samples: 763,144
2025-11-04 10:26:15,356 - INFO - Testing samples: 188,967
2025-11-04 10:26:15,356 - INFO - Supervised (LR) Accuracy: 0.9456
2025-11-04 10:26:15,356 - INFO - Unsupervised (IF) Accuracy: 0.9244
2025-11-04 10:26:15,356 - INFO - Ensemble Accuracy: 0.9456
2025-11-04 10:26:15,356 - INFO - 
Model saved as: models/ensemble.pkl
